# -*- coding: utf-8 -*-
"""xts.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12CJxG1Z0vdS5DYxfX2cpkMAslq3WxAYj

#Análisis de Datos de Precios en Diferentes Nodos (pml y pml.1)
Este jupyter noteebook realiza una serie de análisis sobre un conjunto de datos de precios, incluyendo limpieza de datos, análisis de correlación, regresión lineal y análisis temporal de precios.
"""

# Importando las bibliotecas necesarias
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

# Configuración para mejorar la estética de las gráficas
sns.set(style="whitegrid")

# Cargar y explorar los datos
file_path = 'Data.csv'
try:
    data = pd.read_csv(file_path)
    print("Datos cargados con éxito. Aquí están las primeras filas:")
    print(data.head())
except Exception as e:
    print(f"Ocurrió un error al cargar los datos: {e}")

# Documentación y Análisis Exploratorio de Datos
print("\nAnálisis Exploratorio Inicial:")
print(f"- Total de filas y columnas: {data.shape}")
print(f"- Resumen estadístico:\n{data.describe()}")
print(f"- Información del DataFrame:\n{data.info()}")

"""## Preparación y limpieza de datos (Data cleaning)

Eliminar la columna Unnamed: 0.

Verificar y manejar cualquier valor faltante o incoherente.

Asegurar que las fechas y horas estén en un formato adecuado.
"""

# Eliminar la columna 'Unnamed: 0'
data_cleaned = data.drop(columns=['Unnamed: 0'])

# Verificar valores faltantes antes de las transformaciones
missing_values = data_cleaned.isnull().sum()

# Convertir las columnas de fecha a formato de fecha
data_cleaned['fecha'] = pd.to_datetime(data_cleaned['fecha'], errors='coerce')
data_cleaned['fecha.1'] = pd.to_datetime(data_cleaned['fecha.1'], errors='coerce')

# Asegurar que las horas sean enteros y llenar valores faltantes con 0
data_cleaned['hora'] = data_cleaned['hora'].fillna(0).astype(int)
data_cleaned['hora.1'] = data_cleaned['hora.1'].fillna(0).astype(int)

# Verificar valores faltantes después de las conversiones
missing_values_after = data_cleaned.isnull().sum()

# Mostrar las primeras filas del DataFrame limpio
cleaned_data_head = data_cleaned.head()

print("DataFrame después de la limpieza:")
print(cleaned_data_head)

print("\nValores faltantes antes de las transformaciones:")
print(missing_values)

print("\nValores faltantes después de las transformaciones:")
print(missing_values_after)

"""## Análisis de correlación entre los precios (pml y pml.1) de los dos nodos. ​​"""

# Eliminar filas con valores faltantes
data_cleaned = data_cleaned.dropna()

# Calcular la correlación entre 'pml' y 'pml.1'
correlation = data_cleaned[['pml', 'pml.1']].corr()

correlation

# Configurando el estilo del gráfico
sns.set(style="white")
plt.figure(figsize=(10, 8))

# Creando la matriz de correlación con un mapa de calor
heatmap = sns.heatmap(correlation, annot=True, fmt=".3f", cmap='coolwarm', cbar=True, square=True, linewidths=.5)

# Añadiendo títulos y etiquetas
plt.title('Matriz de Correlación entre pml y pml.1', fontsize=16, pad=20)
plt.xlabel('Variables pml', fontsize=14)
plt.ylabel('Variables pml.1', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.yticks(rotation=0, fontsize=12)

# Añadiendo un mapa de color más legible
cbar = heatmap.collections[0].colorbar
cbar.ax.tick_params(labelsize=12)

# Ajustando el espaciado
plt.tight_layout()

# Mostrando el gráfico
plt.show()

"""### Esta correlación es relativamente baja, lo que indica que, aunque hay alguna relación entre los precios en ambos nodos, no es muy fuerte. Los precios en un nodo no parecen ser predictores muy precisos de los precios en el otro nodo.

## Regresión lineal
"""

# Preparar los datos para la regresión
X = data_cleaned['pml']  # Variable independiente
y = data_cleaned['pml.1']  # Variable dependiente
X = sm.add_constant(X)  # Agregar una constante al modelo

# Realizar la regresión lineal
model = sm.OLS(y, X).fit()

# Resumen de la regresión
regression_summary = model.summary()

# Gráfico de dispersión y línea de regresión
plt.figure(figsize=(12, 6))

# Gráfico de dispersión de datos
plt.scatter(data_cleaned['pml'], data_cleaned['pml.1'], alpha=0.5, label='Datos', color='blue')

# Línea de regresión
plt.plot(data_cleaned['pml'], model.predict(X), color='red', linewidth=2, label='Línea de Regresión')

# Título y etiquetas
plt.title('Regresión Lineal entre Precio de los Dos Nodos', fontsize=16)
plt.xlabel('Precio Nodo 1 (pml)', fontsize=14)
plt.ylabel('Precio Nodo 2 (pml.1)', fontsize=14)

# Leyenda
plt.legend(fontsize=12)

# Cuadrícula
plt.grid(True, linestyle='--', alpha=0.7)

# Mostrar la gráfica
plt.show()

# Imprimir el resumen de la regresión
regression_summary

"""### El gráfico muestra la dispersión de los datos junto con la línea de regresión lineal. Se puede observar que, aunque hay una tendencia positiva, la dispersión de los puntos es bastante amplia, lo que respalda la conclusión de una relación no muy fuerte entre los precios de los nodos.

## Calcular el promedio por hora de cada una de las 24 horas para describir el comportamiento diario de los precios.
"""

# Recargando los datos
file_path = 'Data.csv'
data = pd.read_csv(file_path)

# Limpieza de datos
data_cleaned = data.drop(columns=['Unnamed: 0'])
data_cleaned['fecha'] = pd.to_datetime(data_cleaned['fecha'], errors='coerce')
data_cleaned['fecha.1'] = pd.to_datetime(data_cleaned['fecha.1'], errors='coerce')
data_cleaned['hora'] = data_cleaned['hora'].fillna(0).astype(int)
data_cleaned['hora.1'] = data_cleaned['hora.1'].fillna(0).astype(int)
data_cleaned = data_cleaned.dropna()

# Calcular el promedio por hora para cada nodo
hourly_avg_pml = data_cleaned.groupby('hora')['pml'].mean()
hourly_avg_pml1 = data_cleaned.groupby('hora')['pml.1'].mean()

# Crear un DataFrame para las visualizaciones
hourly_avg = pd.DataFrame({
    'Hora': hourly_avg_pml.index,
    'Precio Promedio Nodo 1': hourly_avg_pml.values,
    'Precio Promedio Nodo 2': hourly_avg_pml1.values
})

# Configuración de estilo
plt.style.use('seaborn-darkgrid')
plt.figure(figsize=(12, 6))

# Gráfico de líneas para los promedios por hora
plt.plot(hourly_avg['Hora'], hourly_avg['Precio Promedio Nodo 1'], label='Precio Promedio Nodo 1', marker='o', linewidth=2)
plt.plot(hourly_avg['Hora'], hourly_avg['Precio Promedio Nodo 2'], label='Precio Promedio Nodo 2', marker='x', linewidth=2)

# Título y etiquetas
plt.title('Precio Promedio por Hora para los Dos Nodos', fontsize=16)
plt.xlabel('Hora del Día', fontsize=14)
plt.ylabel('Precio Promedio', fontsize=14)

# Ejes y leyenda
plt.xticks(np.arange(0, 24, 1))
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(fontsize=12)

# Personalizar el diseño
plt.tight_layout()

# Mostrar la gráfica
plt.show()

# Visualización de los datos
hourly_avg

"""## Encontrar qué mes tiende a ser el más caro y cuál tiende a ser el más barato.

"""

# Asegurándonos de que las fechas estén en formato correcto
data_cleaned['fecha'] = pd.to_datetime(data_cleaned['fecha'], errors='coerce')
data_cleaned['fecha.1'] = pd.to_datetime(data_cleaned['fecha.1'], errors='coerce')

# Extrayendo el mes de las fechas
data_cleaned['mes'] = data_cleaned['fecha'].dt.month

# Calculando el precio promedio por mes
monthly_average = data_cleaned.groupby('mes')[['pml', 'pml.1']].mean().reset_index()

# Definir colores personalizados
colors = ['#007ACC', '#FF4F00']

# Crear la figura y los ejes
fig, ax = plt.subplots(figsize=(12, 6))

# Gráfico de barras
for i, col in enumerate(['pml', 'pml.1']):
    sns.barplot(x='mes', y=col, data=monthly_average, color=colors[i], alpha=0.6, label=col)

# Título y etiquetas
plt.title('Precio Promedio Mensual (pml vs pml.1)', fontsize=16)
plt.xlabel('Mes', fontsize=14)
plt.ylabel('Precio Promedio', fontsize=14)
plt.legend(fontsize=12)
plt.xticks(np.arange(12), ['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre'], rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Agregar anotaciones de valor en las barras
for i, col in enumerate(['pml', 'pml.1']):
    for index, value in enumerate(monthly_average[col]):
        plt.text(index, value, f'{value:.2f}', ha='center', va='bottom', fontsize=10, color=colors[i])

# Añadir línea horizontal promedio
average_line = monthly_average[['pml', 'pml.1']].mean()
plt.axhline(y=average_line[0], color=colors[0], linestyle='--', label=f'Promedio pml ({average_line[0]:.2f})', alpha=0.7)
plt.axhline(y=average_line[1], color=colors[1], linestyle='--', label=f'Promedio pml.1 ({average_line[1]:.2f})', alpha=0.7)

# Personalizar el diseño
sns.despine()
plt.tight_layout()

# Mostrar la gráfica
plt.legend(fontsize=12, loc='upper left')
plt.show()

monthly_average.head(24)

# Convertir las columnas de fecha a formato de fecha y extraer el mes
data['fecha'] = pd.to_datetime(data['fecha'], dayfirst=True)
data['mes'] = data['fecha'].dt.month

# Calcular el precio promedio mensual para cada nodo
precio_promedio_mes = data.groupby('mes').agg({'pml': 'mean', 'pml.1': 'mean'})

# Identificar el mes con el precio promedio más alto y más bajo para cada nodo
mes_mas_caro = precio_promedio_mes.idxmax()
mes_mas_barato = precio_promedio_mes.idxmin()

precio_promedio_mes

mes_mas_caro

mes_mas_barato

# Después de configurar y crear la matriz de correlación

plt.savefig('matriz_correlacion.png')  # Guardar la gráfica como un archivo PNG
plt.show()

# Después de configurar y mostrar el gráfico de regresión
plt.savefig('regresion_lineal.png')  # Guardar la gráfica como un archivo PNG
plt.show()

# Después de configurar y mostrar el gráfico de precio promedio por hora
plt.savefig('precio_promedio_hora.png')  # Guardar la gráfica como un archivo PNG
plt.show()

# Después de configurar y mostrar el gráfico de precio promedio mensual
plt.savefig('precio_promedio_mensual.png')  # Guardar la gráfica como un archivo PNG
plt.show()


"""### Nodo pml
Mes Más Caro: 📈 Diciembre

Precio Promedio: $1951.06

Mes Más Barato: 📉 Marzo

Precio Promedio: $620.72

### Nodo pml.1

Mes Más Caro: 📈 Febrero

Precio Promedio: $1077.42

Mes Más Barato: 📉 Enero

Precio Promedio: $503.07

## Después de completar estas tareas, ¿qué tendencias puedes describir acerca de los datos?

- La correlación de los precios varía de manera bastante independiente.
- Las horas por la tarde presentan precios más elevados que los de la mañana de manera consistente.
- Invierno (21 de diciembre a 21 de marzo) parecen presentar precios más altos.
- Esto puede deberse a la demanda estacional, y comienza a bajar en marzo .
"""
