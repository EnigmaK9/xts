# -*- coding: utf-8 -*-
"""xts.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12CJxG1Z0vdS5DYxfX2cpkMAslq3WxAYj

#An√°lisis de Datos de Precios en Diferentes Nodos (pml y pml.1)
Este jupyter noteebook realiza una serie de an√°lisis sobre un conjunto de datos de precios, incluyendo limpieza de datos, an√°lisis de correlaci√≥n, regresi√≥n lineal y an√°lisis temporal de precios.
"""

# Importando las bibliotecas necesarias
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

# Configuraci√≥n para mejorar la est√©tica de las gr√°ficas
sns.set(style="whitegrid")

# Cargar y explorar los datos
file_path = 'Data.csv'
try:
    data = pd.read_csv(file_path)
    print("Datos cargados con √©xito. Aqu√≠ est√°n las primeras filas:")
    print(data.head())
except Exception as e:
    print(f"Ocurri√≥ un error al cargar los datos: {e}")

# Documentaci√≥n y An√°lisis Exploratorio de Datos
print("\nAn√°lisis Exploratorio Inicial:")
print(f"- Total de filas y columnas: {data.shape}")
print(f"- Resumen estad√≠stico:\n{data.describe()}")
print(f"- Informaci√≥n del DataFrame:\n{data.info()}")

"""## Preparaci√≥n y limpieza de datos (Data cleaning)

Eliminar la columna Unnamed: 0.

Verificar y manejar cualquier valor faltante o incoherente.

Asegurar que las fechas y horas est√©n en un formato adecuado.
"""

# Eliminar la columna 'Unnamed: 0'
data_cleaned = data.drop(columns=['Unnamed: 0'])

# Verificar valores faltantes antes de las transformaciones
missing_values = data_cleaned.isnull().sum()

# Convertir las columnas de fecha a formato de fecha
data_cleaned['fecha'] = pd.to_datetime(data_cleaned['fecha'], errors='coerce')
data_cleaned['fecha.1'] = pd.to_datetime(data_cleaned['fecha.1'], errors='coerce')

# Asegurar que las horas sean enteros y llenar valores faltantes con 0
data_cleaned['hora'] = data_cleaned['hora'].fillna(0).astype(int)
data_cleaned['hora.1'] = data_cleaned['hora.1'].fillna(0).astype(int)

# Verificar valores faltantes despu√©s de las conversiones
missing_values_after = data_cleaned.isnull().sum()

# Mostrar las primeras filas del DataFrame limpio
cleaned_data_head = data_cleaned.head()

print("DataFrame despu√©s de la limpieza:")
print(cleaned_data_head)

print("\nValores faltantes antes de las transformaciones:")
print(missing_values)

print("\nValores faltantes despu√©s de las transformaciones:")
print(missing_values_after)

"""## An√°lisis de correlaci√≥n entre los precios (pml y pml.1) de los dos nodos. ‚Äã‚Äã"""

# Eliminar filas con valores faltantes
data_cleaned = data_cleaned.dropna()

# Calcular la correlaci√≥n entre 'pml' y 'pml.1'
correlation = data_cleaned[['pml', 'pml.1']].corr()

correlation

# Configurando el estilo del gr√°fico
sns.set(style="white")
plt.figure(figsize=(10, 8))

# Creando la matriz de correlaci√≥n con un mapa de calor
heatmap = sns.heatmap(correlation, annot=True, fmt=".3f", cmap='coolwarm', cbar=True, square=True, linewidths=.5)

# A√±adiendo t√≠tulos y etiquetas
plt.title('Matriz de Correlaci√≥n entre pml y pml.1', fontsize=16, pad=20)
plt.xlabel('Variables pml', fontsize=14)
plt.ylabel('Variables pml.1', fontsize=14)
plt.xticks(rotation=45, fontsize=12)
plt.yticks(rotation=0, fontsize=12)

# A√±adiendo un mapa de color m√°s legible
cbar = heatmap.collections[0].colorbar
cbar.ax.tick_params(labelsize=12)

# Ajustando el espaciado
plt.tight_layout()

# Mostrando el gr√°fico
plt.show()

"""### Esta correlaci√≥n es relativamente baja, lo que indica que, aunque hay alguna relaci√≥n entre los precios en ambos nodos, no es muy fuerte. Los precios en un nodo no parecen ser predictores muy precisos de los precios en el otro nodo.

## Regresi√≥n lineal
"""

# Preparar los datos para la regresi√≥n
X = data_cleaned['pml']  # Variable independiente
y = data_cleaned['pml.1']  # Variable dependiente
X = sm.add_constant(X)  # Agregar una constante al modelo

# Realizar la regresi√≥n lineal
model = sm.OLS(y, X).fit()

# Resumen de la regresi√≥n
regression_summary = model.summary()

# Gr√°fico de dispersi√≥n y l√≠nea de regresi√≥n
plt.figure(figsize=(12, 6))

# Gr√°fico de dispersi√≥n de datos
plt.scatter(data_cleaned['pml'], data_cleaned['pml.1'], alpha=0.5, label='Datos', color='blue')

# L√≠nea de regresi√≥n
plt.plot(data_cleaned['pml'], model.predict(X), color='red', linewidth=2, label='L√≠nea de Regresi√≥n')

# T√≠tulo y etiquetas
plt.title('Regresi√≥n Lineal entre Precio de los Dos Nodos', fontsize=16)
plt.xlabel('Precio Nodo 1 (pml)', fontsize=14)
plt.ylabel('Precio Nodo 2 (pml.1)', fontsize=14)

# Leyenda
plt.legend(fontsize=12)

# Cuadr√≠cula
plt.grid(True, linestyle='--', alpha=0.7)

# Mostrar la gr√°fica
plt.show()

# Imprimir el resumen de la regresi√≥n
regression_summary

"""### El gr√°fico muestra la dispersi√≥n de los datos junto con la l√≠nea de regresi√≥n lineal. Se puede observar que, aunque hay una tendencia positiva, la dispersi√≥n de los puntos es bastante amplia, lo que respalda la conclusi√≥n de una relaci√≥n no muy fuerte entre los precios de los nodos.

## Calcular el promedio por hora de cada una de las 24 horas para describir el comportamiento diario de los precios.
"""

# Recargando los datos
file_path = 'Data.csv'
data = pd.read_csv(file_path)

# Limpieza de datos
data_cleaned = data.drop(columns=['Unnamed: 0'])
data_cleaned['fecha'] = pd.to_datetime(data_cleaned['fecha'], errors='coerce')
data_cleaned['fecha.1'] = pd.to_datetime(data_cleaned['fecha.1'], errors='coerce')
data_cleaned['hora'] = data_cleaned['hora'].fillna(0).astype(int)
data_cleaned['hora.1'] = data_cleaned['hora.1'].fillna(0).astype(int)
data_cleaned = data_cleaned.dropna()

# Calcular el promedio por hora para cada nodo
hourly_avg_pml = data_cleaned.groupby('hora')['pml'].mean()
hourly_avg_pml1 = data_cleaned.groupby('hora')['pml.1'].mean()

# Crear un DataFrame para las visualizaciones
hourly_avg = pd.DataFrame({
    'Hora': hourly_avg_pml.index,
    'Precio Promedio Nodo 1': hourly_avg_pml.values,
    'Precio Promedio Nodo 2': hourly_avg_pml1.values
})

# Configuraci√≥n de estilo
plt.style.use('seaborn-darkgrid')
plt.figure(figsize=(12, 6))

# Gr√°fico de l√≠neas para los promedios por hora
plt.plot(hourly_avg['Hora'], hourly_avg['Precio Promedio Nodo 1'], label='Precio Promedio Nodo 1', marker='o', linewidth=2)
plt.plot(hourly_avg['Hora'], hourly_avg['Precio Promedio Nodo 2'], label='Precio Promedio Nodo 2', marker='x', linewidth=2)

# T√≠tulo y etiquetas
plt.title('Precio Promedio por Hora para los Dos Nodos', fontsize=16)
plt.xlabel('Hora del D√≠a', fontsize=14)
plt.ylabel('Precio Promedio', fontsize=14)

# Ejes y leyenda
plt.xticks(np.arange(0, 24, 1))
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(fontsize=12)

# Personalizar el dise√±o
plt.tight_layout()

# Mostrar la gr√°fica
plt.show()

# Visualizaci√≥n de los datos
hourly_avg

"""## Encontrar qu√© mes tiende a ser el m√°s caro y cu√°l tiende a ser el m√°s barato.

"""

# Asegur√°ndonos de que las fechas est√©n en formato correcto
data_cleaned['fecha'] = pd.to_datetime(data_cleaned['fecha'], errors='coerce')
data_cleaned['fecha.1'] = pd.to_datetime(data_cleaned['fecha.1'], errors='coerce')

# Extrayendo el mes de las fechas
data_cleaned['mes'] = data_cleaned['fecha'].dt.month

# Calculando el precio promedio por mes
monthly_average = data_cleaned.groupby('mes')[['pml', 'pml.1']].mean().reset_index()

# Definir colores personalizados
colors = ['#007ACC', '#FF4F00']

# Crear la figura y los ejes
fig, ax = plt.subplots(figsize=(12, 6))

# Gr√°fico de barras
for i, col in enumerate(['pml', 'pml.1']):
    sns.barplot(x='mes', y=col, data=monthly_average, color=colors[i], alpha=0.6, label=col)

# T√≠tulo y etiquetas
plt.title('Precio Promedio Mensual (pml vs pml.1)', fontsize=16)
plt.xlabel('Mes', fontsize=14)
plt.ylabel('Precio Promedio', fontsize=14)
plt.legend(fontsize=12)
plt.xticks(np.arange(12), ['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre'], rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Agregar anotaciones de valor en las barras
for i, col in enumerate(['pml', 'pml.1']):
    for index, value in enumerate(monthly_average[col]):
        plt.text(index, value, f'{value:.2f}', ha='center', va='bottom', fontsize=10, color=colors[i])

# A√±adir l√≠nea horizontal promedio
average_line = monthly_average[['pml', 'pml.1']].mean()
plt.axhline(y=average_line[0], color=colors[0], linestyle='--', label=f'Promedio pml ({average_line[0]:.2f})', alpha=0.7)
plt.axhline(y=average_line[1], color=colors[1], linestyle='--', label=f'Promedio pml.1 ({average_line[1]:.2f})', alpha=0.7)

# Personalizar el dise√±o
sns.despine()
plt.tight_layout()

# Mostrar la gr√°fica
plt.legend(fontsize=12, loc='upper left')
plt.show()

monthly_average.head(24)

# Convertir las columnas de fecha a formato de fecha y extraer el mes
data['fecha'] = pd.to_datetime(data['fecha'], dayfirst=True)
data['mes'] = data['fecha'].dt.month

# Calcular el precio promedio mensual para cada nodo
precio_promedio_mes = data.groupby('mes').agg({'pml': 'mean', 'pml.1': 'mean'})

# Identificar el mes con el precio promedio m√°s alto y m√°s bajo para cada nodo
mes_mas_caro = precio_promedio_mes.idxmax()
mes_mas_barato = precio_promedio_mes.idxmin()

precio_promedio_mes

mes_mas_caro

mes_mas_barato

# Despu√©s de configurar y crear la matriz de correlaci√≥n

plt.savefig('matriz_correlacion.png')  # Guardar la gr√°fica como un archivo PNG
plt.show()

# Despu√©s de configurar y mostrar el gr√°fico de regresi√≥n
plt.savefig('regresion_lineal.png')  # Guardar la gr√°fica como un archivo PNG
plt.show()

# Despu√©s de configurar y mostrar el gr√°fico de precio promedio por hora
plt.savefig('precio_promedio_hora.png')  # Guardar la gr√°fica como un archivo PNG
plt.show()

# Despu√©s de configurar y mostrar el gr√°fico de precio promedio mensual
plt.savefig('precio_promedio_mensual.png')  # Guardar la gr√°fica como un archivo PNG
plt.show()


"""### Nodo pml
Mes M√°s Caro: üìà Diciembre

Precio Promedio: $1951.06

Mes M√°s Barato: üìâ Marzo

Precio Promedio: $620.72

### Nodo pml.1

Mes M√°s Caro: üìà Febrero

Precio Promedio: $1077.42

Mes M√°s Barato: üìâ Enero

Precio Promedio: $503.07

## Despu√©s de completar estas tareas, ¬øqu√© tendencias puedes describir acerca de los datos?

- La correlaci√≥n de los precios var√≠a de manera bastante independiente.
- Las horas por la tarde presentan precios m√°s elevados que los de la ma√±ana de manera consistente.
- Invierno (21 de diciembre a 21 de marzo) parecen presentar precios m√°s altos.
- Esto puede deberse a la demanda estacional, y comienza a bajar en marzo .
"""
